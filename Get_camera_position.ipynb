{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Intrinsics:\n",
      "Width: 640\n",
      "Height: 480\n",
      "Focal Length: (fx=607.0476684570312, fy=606.38427734375)\n",
      "Principal Point: (cx=317.7261962890625, cy=230.09971618652344)\n",
      "\n",
      "Depth Intrinsics:\n",
      "Width: 640\n",
      "Height: 480\n",
      "Focal Length: (fx=589.3923950195312, fy=589.3923950195312)\n",
      "Principal Point: (cx=314.98797607421875, cy=242.5380859375)\n",
      "3D world coordinates of corners:\n",
      "[[  43.993927     40.08396149  983.00006104]\n",
      " [  72.78414917   40.37263107  985.00006104]\n",
      " [ 101.92642975   40.84933853  985.00006104]\n",
      " [ 130.88581848   41.21699142  984.        ]\n",
      " [ 160.27853394   41.70043945  989.        ]\n",
      " [ 189.5683136    41.92135239  990.00006104]\n",
      " [ 221.3722229    42.56097412 1000.        ]\n",
      " [ 251.64576721   42.86922836 1003.        ]\n",
      " [  43.79205704   68.75491333  982.00006104]\n",
      " [  72.61325836   69.39443207  983.00006104]\n",
      " [ 101.42003632   69.77030945  984.        ]\n",
      " [ 130.92440796   70.16841125  986.00006104]\n",
      " [ 159.91317749   70.25945282  987.00006104]\n",
      " [ 189.54402161   70.8744812   990.00006104]\n",
      " [ 219.1191864    71.18321991  990.00006104]\n",
      " [ 248.4337616    71.9190979   991.00006104]\n",
      " [  43.26527405   97.94650269  981.00006104]\n",
      " [  72.65123749   98.49475098  985.00006104]\n",
      " [ 101.35955048   98.72706604  985.00006104]\n",
      " [ 131.14337158   99.12101746  988.00006104]\n",
      " [ 159.50238037   99.31076813  985.00006104]\n",
      " [ 188.99208069  100.13694     988.00006104]\n",
      " [ 218.58673096  100.51821136  988.00006104]\n",
      " [ 248.56518555  101.05506134  992.00006104]\n",
      " [  43.07430649  126.88782501  983.00006104]\n",
      " [  72.521492    127.48096466  985.00006104]\n",
      " [ 101.14022064  127.77294159  984.        ]\n",
      " [ 131.06028748  128.76878357  988.00006104]\n",
      " [ 159.98817444  128.93626404  988.00006104]\n",
      " [ 188.91822815  129.13371277  987.00006104]\n",
      " [ 219.29295349  129.79003906  991.00006104]\n",
      " [ 248.5774231   130.60591125  990.00006104]\n",
      " [  42.78566742  156.40994263  983.00006104]\n",
      " [  72.25595093  156.57713318  983.00006104]\n",
      " [ 100.70742798  156.45304871  981.00006104]\n",
      " [ 130.60658264  157.15713501  985.00006104]\n",
      " [ 159.46734619  157.63217163  985.00006104]\n",
      " [ 189.28765869  158.85321045  988.00006104]\n",
      " [ 218.81161499  159.15574646  988.00006104]\n",
      " [ 248.8150177   159.2913208   988.00006104]\n",
      " [  42.58759689  185.06677246  980.        ]\n",
      " [  72.05034637  185.83222961  982.00006104]\n",
      " [ 101.02899933  186.3526001   983.00006104]\n",
      " [ 130.76219177  187.09085083  985.00006104]\n",
      " [ 160.21377563  187.90219116  988.00006104]\n",
      " [ 189.5123291   188.21159363  986.00006104]\n",
      " [ 219.17677307  188.61584473  985.00006104]\n",
      " [ 248.52601624  188.98060608  985.00006104]]\n",
      "Homography Matrix H:\n",
      "[[ 6.05746949e-01 -3.00313786e-02  3.15507964e+02]\n",
      " [ 8.99993420e-03  5.70833967e-01  2.42894645e+02]\n",
      " [ 3.74112961e-05 -8.40827757e-05  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "# Setup RealSense pipeline\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "# Enable both color (RGB) and depth streams\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "# Start the pipeline\n",
    "pipeline.start(config)\n",
    "\n",
    "# Wait for the first valid frame\n",
    "frames = pipeline.wait_for_frames()\n",
    "\n",
    "# Get color and depth frames\n",
    "color_frame = frames.get_color_frame()\n",
    "depth_frame = frames.get_depth_frame()\n",
    "\n",
    "# Convert to numpy arrays\n",
    "color_image = np.asanyarray(color_frame.get_data())\n",
    "depth_image = np.asanyarray(depth_frame.get_data())\n",
    "\n",
    "# Get the color camera intrinsics\n",
    "color_intrinsics = color_frame.profile.as_video_stream_profile().get_intrinsics()\n",
    "\n",
    "# Print the intrinsic parameters\n",
    "print(\"Color Intrinsics:\")\n",
    "print(f\"Width: {color_intrinsics.width}\")\n",
    "print(f\"Height: {color_intrinsics.height}\")\n",
    "print(f\"Focal Length: (fx={color_intrinsics.fx}, fy={color_intrinsics.fy})\")\n",
    "print(f\"Principal Point: (cx={color_intrinsics.ppx}, cy={color_intrinsics.ppy})\")\n",
    "\n",
    "# Get the depth camera intrinsics (you can use the depth stream's intrinsics similarly)\n",
    "depth_intrinsics = depth_frame.profile.as_video_stream_profile().get_intrinsics()\n",
    "\n",
    "print(\"\\nDepth Intrinsics:\")\n",
    "print(f\"Width: {depth_intrinsics.width}\")\n",
    "print(f\"Height: {depth_intrinsics.height}\")\n",
    "print(f\"Focal Length: (fx={depth_intrinsics.fx}, fy={depth_intrinsics.fy})\")\n",
    "print(f\"Principal Point: (cx={depth_intrinsics.ppx}, cy={depth_intrinsics.ppy})\")\n",
    "\n",
    "# Define chessboard pattern size (number of inner corners, e.g., 9x6 chessboard)\n",
    "pattern_size = (8, 6)  # 9 columns, 6 rows of inner corners\n",
    "\n",
    "# Convert the color image to grayscale\n",
    "gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find chessboard corners\n",
    "ret, corners = cv2.findChessboardCorners(gray, pattern_size)\n",
    "\n",
    "if ret:\n",
    "    # Refine corner locations for subpixel accuracy\n",
    "    cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1),\n",
    "                     criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1))\n",
    "\n",
    "    # Draw detected corners for visualization\n",
    "    cv2.drawChessboardCorners(color_image, pattern_size, corners, ret)\n",
    "    cv2.imshow('Detected Chessboard Corners', color_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Chessboard corners not detected.\")\n",
    "\n",
    "\n",
    "# Assuming we have the corners detected, let's map them to 3D world coordinates\n",
    "world_points = []\n",
    "\n",
    "for corner in corners:\n",
    "    x, y = corner.ravel()\n",
    "\n",
    "    # Get the depth value for the current pixel (in millimeters)\n",
    "    depth = depth_frame.get_distance(int(x), int(y))*1000  # depth in meters\n",
    "    if depth > 0:\n",
    "        # Back-project the 2D pixel to 3D world coordinates\n",
    "        world_point = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [x, y], depth)\n",
    "        world_points.append(world_point)\n",
    "\n",
    "world_points = np.array(world_points)\n",
    "print(\"3D world coordinates of corners:\")\n",
    "print(world_points)\n",
    "\n",
    "# The 3D points (world coordinates) need to be converted to 2D coordinates in the world plane (Z=0)\n",
    "# If the world points are in 3D (x, y, z), let's consider the x and y values (flattening the Z dimension)\n",
    "\n",
    "# Convert 3D world points to 2D (assuming Z=0)\n",
    "world_points_2d = world_points[:, :2]  # Only use the x and y coordinates\n",
    "\n",
    "# Now compute the homography matrix between the 2D image points and 2D world points\n",
    "H, _ = cv2.findHomography(world_points_2d, corners.reshape(-1, 2))\n",
    "\n",
    "print(\"Homography Matrix H:\")\n",
    "print(H)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Show the color image\n",
    "cv2.imshow('Color Image', color_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "pipeline.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 - Reprojection Error: 0.15258733266474747\n",
      "Calibration complete - Reprojection error is below threshold.\n",
      "Final Homography Matrix H:\n",
      "[[ 6.09542798e-01 -1.67279102e-02  2.93828535e+02]\n",
      " [-5.70913915e-03  5.98333405e-01  2.25283837e+02]\n",
      " [-1.39341271e-05 -5.77484196e-05  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "# Setup RealSense pipeline\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "# Enable both color (RGB) and depth streams\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "# Start the pipeline\n",
    "pipeline.start(config)\n",
    "\n",
    "# Wait for the first valid frame\n",
    "frames = pipeline.wait_for_frames()\n",
    "\n",
    "# Get color and depth frames\n",
    "color_frame = frames.get_color_frame()\n",
    "depth_frame = frames.get_depth_frame()\n",
    "\n",
    "# Convert to numpy arrays\n",
    "color_image = np.asanyarray(color_frame.get_data())\n",
    "depth_image = np.asanyarray(depth_frame.get_data())\n",
    "\n",
    "# Get the color camera intrinsics\n",
    "color_intrinsics = color_frame.profile.as_video_stream_profile().get_intrinsics()\n",
    "\n",
    "# Get the depth camera intrinsics\n",
    "depth_intrinsics = depth_frame.profile.as_video_stream_profile().get_intrinsics()\n",
    "\n",
    "# Define chessboard pattern size (number of inner corners, e.g., 9x6 chessboard)\n",
    "pattern_size = (8, 6)  # 9 columns, 6 rows of inner corners\n",
    "\n",
    "# Define the real-world square size (in meters, e.g., 20 mm = 0.02 m)\n",
    "square_size = 0.028*1000  # 20mm per square\n",
    "\n",
    "# Threshold for the reprojection error (in pixels)\n",
    "reprojection_error_threshold = 0.5  # You can adjust this threshold\n",
    "\n",
    "# Function to compute the reprojection error\n",
    "def compute_reprojection_error(image_points, world_points, H):\n",
    "    \"\"\"\n",
    "    Computes the mean reprojection error between the image points and\n",
    "    the points reprojected from the world points using the homography matrix H.\n",
    "    \"\"\"\n",
    "    projected_points = []\n",
    "    \n",
    "    for point in world_points:\n",
    "        world_point_2d = np.array([point[0], point[1], 1.0])  # Homogeneous coordinates\n",
    "        projected_point = H.dot(world_point_2d)\n",
    "        projected_point /= projected_point[2]  # Normalize by z to get the 2D point\n",
    "        \n",
    "        projected_points.append(projected_point[:2])  # Take only x, y\n",
    "\n",
    "    projected_points = np.array(projected_points)\n",
    "\n",
    "    # Calculate the Euclidean distance between the projected points and the actual image points\n",
    "    error = np.sqrt(np.sum((projected_points - image_points) ** 2, axis=1))\n",
    "    \n",
    "    # Return the mean reprojection error\n",
    "    return np.mean(error)\n",
    "\n",
    "# Loop for calibration until the error is below the threshold\n",
    "iteration = 0\n",
    "while True:\n",
    "    # Convert the color image to grayscale\n",
    "    gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, pattern_size)\n",
    "\n",
    "    if ret:\n",
    "        # Refine corner locations for subpixel accuracy\n",
    "        cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1),\n",
    "                         criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1))\n",
    "\n",
    "        # Draw detected corners for visualization\n",
    "        cv2.drawChessboardCorners(color_image, pattern_size, corners, ret)\n",
    "        cv2.imshow('Detected Chessboard Corners', color_image)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "        # Map the corners to 3D world coordinates\n",
    "        world_points = []\n",
    "\n",
    "        for row in range(pattern_size[1]):  # For each row in the checkerboard\n",
    "            for col in range(pattern_size[0]):  # For each column in the checkerboard\n",
    "                # The world coordinates of each corner based on its grid position\n",
    "                world_point = np.array([col * square_size, row * square_size, 0])  # Z=0 for the checkerboard plane\n",
    "                world_points.append(world_point)\n",
    "\n",
    "        world_points = np.array(world_points)\n",
    "\n",
    "        # Convert 3D world points to 2D (Z=0) by ignoring the z-coordinate\n",
    "        world_points_2d = world_points[:, :2]  # Only use x and y for 2D homography\n",
    "\n",
    "        # Compute the homography matrix between the 2D image points and 2D world points\n",
    "        H, _ = cv2.findHomography(world_points_2d, corners.reshape(-1, 2))\n",
    "\n",
    "        # Compute the reprojection error\n",
    "        reprojection_error = compute_reprojection_error(corners.reshape(-1, 2), world_points_2d, H)\n",
    "\n",
    "        print(f\"Iteration {iteration} - Reprojection Error: {reprojection_error}\")\n",
    "\n",
    "        # Check if the reprojection error is below the threshold\n",
    "        if reprojection_error < reprojection_error_threshold:\n",
    "            print(\"Calibration complete - Reprojection error is below threshold.\")\n",
    "            break\n",
    "\n",
    "        # Increment the iteration counter\n",
    "        iteration += 1\n",
    "\n",
    "    else:\n",
    "        print(\"Chessboard corners not detected.\")\n",
    "\n",
    "    # Stop the pipeline after the calibration is complete\n",
    "    pipeline.stop()\n",
    "\n",
    "# Final Homography matrix\n",
    "print(\"Final Homography Matrix H:\")\n",
    "print(H)\n",
    "\n",
    "# Show the color image\n",
    "cv2.imshow('Color Image', color_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "# Setup RealSense pipeline\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "# Enable both color (RGB) and depth streams\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "# Start the pipeline\n",
    "pipeline.start(config)\n",
    "\n",
    "# Wait for the first valid frame\n",
    "frames = pipeline.wait_for_frames()\n",
    "\n",
    "# Get color and depth frames\n",
    "color_frame = frames.get_color_frame()\n",
    "depth_frame = frames.get_depth_frame()\n",
    "\n",
    "# Convert to numpy arrays\n",
    "color_image = np.asanyarray(color_frame.get_data())\n",
    "depth_image = np.asanyarray(depth_frame.get_data())\n",
    "\n",
    "# Get the color camera intrinsics\n",
    "color_intrinsics = color_frame.profile.as_video_stream_profile().get_intrinsics()\n",
    "\n",
    "# Get the depth camera intrinsics\n",
    "depth_intrinsics = depth_frame.profile.as_video_stream_profile().get_intrinsics()\n",
    "\n",
    "\n",
    "# Get the size of the original image\n",
    "height, width = color_image.shape[:2]\n",
    "\n",
    "# Optionally, you can compute the bounding box of the transformed image, to avoid clipping\n",
    "corners = np.array([[0, 0], [width-1, 0], [0, height-1], [width-1, height-1]], dtype=np.float32)\n",
    "transformed_corners = cv2.perspectiveTransform(corners[None, :, :], H)\n",
    "\n",
    "# Get the bounding box of the transformed corners\n",
    "min_x, min_y = np.min(transformed_corners, axis=1).ravel()\n",
    "max_x, max_y = np.max(transformed_corners, axis=1).ravel()\n",
    "\n",
    "# Compute the size of the output image\n",
    "output_width = int(max_x - min_x)\n",
    "output_height = int(max_y - min_y)\n",
    "\n",
    "# Translate the homography to ensure the transformed image is properly placed\n",
    "translation_matrix = np.array([[1, 0, -min_x], [0, 1, -min_y], [0, 0, 1]])\n",
    "adjusted_H = translation_matrix @ H\n",
    "\n",
    "# Apply the adjusted homography to get the top-down view\n",
    "depth_image = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.25), cv2.COLORMAP_VIRIDIS)\n",
    "top_down_color = cv2.warpPerspective(color_image, adjusted_H, (output_width, output_height))\n",
    "top_down_depth = cv2.warpPerspective(depth_image, adjusted_H, (output_width, output_height))\n",
    "\n",
    "\n",
    "scale_factor = 1.5\n",
    "top_down_color = cv2.resize(top_down_color,None,fx =  scale_factor,fy = scale_factor)\n",
    " \n",
    "top_down_depth = cv2.resize(top_down_depth,None,fx =  scale_factor,fy = scale_factor)\n",
    "# Show the top-down images\n",
    "cv2.imshow('Original Frae',color_image )\n",
    "cv2.imshow(\"Top-Down Color Image\", top_down_color)\n",
    "cv2.imshow(\"Top-Down Depth Image\", top_down_depth)\n",
    "\n",
    "# Wait for a key press before closing the windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforation Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_H = False\n",
    "if get_H == True:\n",
    "\n",
    "\n",
    "    pipeline = rs.pipeline()\n",
    "    config = rs.config()\n",
    "    config.enable_stream(rs.stream.color, 1920, 1080, rs.format.bgr8, framerate = 30)\n",
    "    config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, framerate = 30)\n",
    "\n",
    "    #create align object\n",
    "    align_to = rs.stream.color\n",
    "    align = rs.align(align_to)\n",
    "\n",
    "    # Start the pipeline\n",
    "    pipeline.start(config)\n",
    "\n",
    "    # Wait for the first valid frame\n",
    "    frames = pipeline.wait_for_frames()\n",
    "\n",
    "    # Get color and depth frames\n",
    "    color_frame = frames.get_color_frame()\n",
    "    depth_frame = frames.get_depth_frame()\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    depth_image = np.asanyarray(depth_frame.get_data())\n",
    "\n",
    "    # Get the color camera intrinsics\n",
    "    color_intrinsics = color_frame.profile.as_video_stream_profile().get_intrinsics()\n",
    "\n",
    "    # Get the depth camera intrinsics\n",
    "    depth_intrinsics = depth_frame.profile.as_video_stream_profile().get_intrinsics()\n",
    "\n",
    "    # Define chessboard pattern size (number of inner corners, e.g., 9x6 chessboard)\n",
    "    pattern_size = (8, 6)  # 9 columns, 6 rows of inner corners\n",
    "\n",
    "    # Define the real-world square size (in meters, e.g., 20 mm = 0.02 m)\n",
    "    square_size = 0.028*1000  # 20mm per square\n",
    "\n",
    "    # Threshold for the reprojection error (in pixels)\n",
    "    reprojection_error_threshold = 0.5  # You can adjust this threshold\n",
    "\n",
    "    # Function to compute the reprojection error\n",
    "    def compute_reprojection_error(image_points, world_points, H):\n",
    "        \"\"\"\n",
    "        Computes the mean reprojection error between the image points and\n",
    "        the points reprojected from the world points using the homography matrix H.\n",
    "        \"\"\"\n",
    "        projected_points = []\n",
    "        \n",
    "        for point in world_points:\n",
    "            world_point_2d = np.array([point[0], point[1], 1.0])  # Homogeneous coordinates\n",
    "            projected_point = H.dot(world_point_2d)\n",
    "            projected_point /= projected_point[2]  # Normalize by z to get the 2D point\n",
    "            \n",
    "            projected_points.append(projected_point[:2])  # Take only x, y\n",
    "\n",
    "        projected_points = np.array(projected_points)\n",
    "\n",
    "        # Calculate the Euclidean distance between the projected points and the actual image points\n",
    "        error = np.sqrt(np.sum((projected_points - image_points) ** 2, axis=1))\n",
    "        \n",
    "        # Return the mean reprojection error\n",
    "        return np.mean(error)\n",
    "\n",
    "    # Loop for calibration until the error is below the threshold\n",
    "    iteration = 0\n",
    "    while True:\n",
    "        # Convert the color image to grayscale\n",
    "        gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, pattern_size)\n",
    "\n",
    "        if ret:\n",
    "            # Refine corner locations for subpixel accuracy\n",
    "            cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1),\n",
    "                            criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.1))\n",
    "\n",
    "            # Draw detected corners for visualization\n",
    "            cv2.drawChessboardCorners(color_image, pattern_size, corners, ret)\n",
    "            cv2.imshow('Detected Chessboard Corners', color_image)\n",
    "            cv2.waitKey(0)\n",
    "\n",
    "            # Map the corners to 3D world coordinates\n",
    "            world_points = []\n",
    "\n",
    "            for row in range(pattern_size[1]):  # For each row in the checkerboard\n",
    "                for col in range(pattern_size[0]):  # For each column in the checkerboard\n",
    "                    # The world coordinates of each corner based on its grid position\n",
    "                    world_point = np.array([col * square_size, row * square_size, 0])  # Z=0 for the checkerboard plane\n",
    "                    world_points.append(world_point)\n",
    "\n",
    "            world_points = np.array(world_points)\n",
    "\n",
    "            # Convert 3D world points to 2D (Z=0) by ignoring the z-coordinate\n",
    "            world_points_2d = world_points[:, :2]  # Only use x and y for 2D homography\n",
    "\n",
    "            # Compute the homography matrix between the 2D image points and 2D world points\n",
    "            H, _ = cv2.findHomography(world_points_2d, corners.reshape(-1, 2))\n",
    "\n",
    "            # Compute the reprojection error\n",
    "            reprojection_error = compute_reprojection_error(corners.reshape(-1, 2), world_points_2d, H)\n",
    "\n",
    "            print(f\"Iteration {iteration} - Reprojection Error: {reprojection_error}\")\n",
    "\n",
    "            # Check if the reprojection error is below the threshold\n",
    "            if reprojection_error < reprojection_error_threshold:\n",
    "                print(\"Calibration complete - Reprojection error is below threshold.\")\n",
    "                break\n",
    "\n",
    "            # Increment the iteration counter\n",
    "            iteration += 1\n",
    "\n",
    "        else:\n",
    "            print(\"Chessboard corners not detected.\")\n",
    "\n",
    "        # Stop the pipeline after the calibration is complete\n",
    "        pipeline.stop()\n",
    "\n",
    "    # Final Homography matrix\n",
    "    print(\"Final Homography Matrix H:\")\n",
    "    print(H)\n",
    "\n",
    "    # Show the color image\n",
    "    cv2.imshow('Color Image', color_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def get_top_down_view(color_image, depth_image, H):\n",
    "    # Get the color camera intrinsics\n",
    "    #color_intrinsics = color_frame.profile.as_video_stream_profile().get_intrinsics()\n",
    "\n",
    "    # Get the depth camera intrinsics\n",
    "    #depth_intrinsics = depth_frame.profile.as_video_stream_profile().get_intrinsics()\n",
    "\n",
    "\n",
    "    # Get the size of the original image\n",
    "    height, width = color_image.shape[:2]\n",
    "\n",
    "    # Optionally, you can compute the bounding box of the transformed image, to avoid clipping\n",
    "    corners = np.array([[0, 0], [width-1, 0], [0, height-1], [width-1, height-1]], dtype=np.float32)\n",
    "    transformed_corners = cv2.perspectiveTransform(corners[None, :, :], H)\n",
    "\n",
    "    # Get the bounding box of the transformed corners\n",
    "    min_x, min_y = np.min(transformed_corners, axis=1).ravel()\n",
    "    max_x, max_y = np.max(transformed_corners, axis=1).ravel()\n",
    "\n",
    "    # Compute the size of the output image\n",
    "    output_width = int(max_x - min_x)\n",
    "    output_height = int(max_y - min_y)\n",
    "\n",
    "    # Translate the homography to ensure the transformed image is properly placed\n",
    "    translation_matrix = np.array([[1, 0, -min_x], [0, 1, -min_y], [0, 0, 1]])\n",
    "    adjusted_H = translation_matrix @ H\n",
    "\n",
    "    # Apply the adjusted homography to get the top-down view\n",
    "    depth_image_color_map = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.25), cv2.COLORMAP_VIRIDIS)\n",
    "    top_down_color = cv2.warpPerspective(color_image, adjusted_H, (output_width, output_height))\n",
    "    top_down_depth = cv2.warpPerspective(depth_image, adjusted_H, (output_width, output_height))\n",
    "\n",
    "\n",
    "    scale_factor = 0.5\n",
    "    top_down_color = cv2.resize(top_down_color,None,fx =  scale_factor,fy = scale_factor)\n",
    "    \n",
    "    top_down_depth = cv2.resize(top_down_depth,None,fx =  scale_factor,fy = scale_factor)\n",
    "    # Show the top-down images\n",
    "   \n",
    "    #cv2.imshow(\"Top-Down Color Image\", top_down_color)\n",
    "    #cv2.imshow(\"Top-Down Depth Image\", top_down_depth)\n",
    "    return top_down_color,top_down_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_H' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Improve Depth Image\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mget_H\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m     top_down_color, top_down_depth \u001b[38;5;241m=\u001b[39m get_top_down_view(color_image, depth_image, H)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m get_H \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_H' is not defined"
     ]
    }
   ],
   "source": [
    "#Improve Depth Image\n",
    "\n",
    "if get_H == True:\n",
    "                masked_color_image_top_down,cropped_image_top_down, hull,box,box_detected = cut_region_between_hulls(top_down_depth,top_down_color,min_depth =0,max_depth = cutting_depth, factor= 0.12, cut_rect= True, improved_bounding_box= False)\n",
    "            #box_detected = False\n",
    "if get_H == True:\n",
    "    top_down_color, top_down_depth = get_top_down_view(color_image, depth_image, H)\n",
    "\n",
    "if get_H == True:\n",
    "    if masked_color_image_top_down is not None and   isinstance(masked_color_image_top_down, np.ndarray):\n",
    "        print(masked_color_image_top_down)\n",
    "        resized_masked_image = cv2.resize(masked_color_image_top_down,None,fx =  scale_factor,fy = scale_factor)\n",
    "        # Create the top horizontal stack\n",
    "        \n",
    "        cv2.imshow('Color Images top down', resized_masked_image)\n",
    "    else:\n",
    "        cv2.imshow('Color Images top down', resized_masked_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "binsertion-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
