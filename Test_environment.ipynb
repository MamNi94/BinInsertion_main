{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "import os\n",
    "os.environ['QT_QPA_PLATFORM'] = 'xcb'\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import heapq\n",
    "\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "\n",
    "\n",
    "from video_capture import capture_frames\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(p1, p2):\n",
    "    \"\"\" Calculate the Euclidean distance between two points. \"\"\"\n",
    "    return np.linalg.norm(np.array(p1) - np.array(p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_region(depth_image,color_image,min_depth = 0,max_depth = 0.8):\n",
    "  \n",
    "    min_depth_mm = min_depth * 1000\n",
    "    max_depth_mm = max_depth * 1000\n",
    "\n",
    "    # Create a mask for the specified depth range\n",
    "    mask = np.logical_and(depth_image > min_depth_mm, depth_image < max_depth_mm)\n",
    "\n",
    "    # Convert mask to uint8\n",
    "    mask = mask.astype(np.uint8) * 255\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # Create an empty mask to draw the contour region\n",
    "    contour_mask = np.zeros_like(mask)\n",
    "        # Check if any contours were found\n",
    "    if contours:\n",
    "        all_points = np.concatenate(contours)\n",
    "        hull = cv2.convexHull(all_points)\n",
    "        # Draw the filled contour on the contour_mask\n",
    "        cv2.drawContours(contour_mask, [hull], -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "        rect = cv2.minAreaRect(hull)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "        cv2.drawContours(color_image, [box], 0, (125, 125, 255), 5)\n",
    "        cv2.drawContours(color_image, [hull], 0, (0, 255, 0), 5)\n",
    "        \n",
    "\n",
    "    masked_color_image = cv2.bitwise_and(color_image, color_image, mask=contour_mask)\n",
    "    \n",
    "                \n",
    "    return masked_color_image, hull,box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(p1, p2):\n",
    "    return math.sqrt((p2[0] - p1[0]) ** 2 + (p2[1] - p1[1]) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_from_points(p1, p2):\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    \n",
    "    # Calculate slope (m)\n",
    "    if x2 != x1:\n",
    "        m = (y2 - y1) / (x2 - x1)\n",
    "    else:\n",
    "        raise ValueError(\"The x-coordinates of the points cannot be the same.\")\n",
    "    \n",
    "    # Calculate y-intercept (b)\n",
    "    b = y1 - m * x1\n",
    "    \n",
    "    return m, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_intercection(m1,m2,q1,q2):\n",
    "    \n",
    "    x = (q2-q1) / (m1-m2) \n",
    "    y = m1*x+q1\n",
    "    \n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    p = tuple([x,y])\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_point_on_line(p1, p2, point, distance):\n",
    "    \"\"\"\n",
    "    Move a point along the line defined by p1 and p2 by a certain distance.\n",
    "    \n",
    "    Parameters:\n",
    "    p1 (tuple): First point defining the line (x1, y1).\n",
    "    p2 (tuple): Second point defining the line (x2, y2).\n",
    "    point (tuple): The point to move (x, y).\n",
    "    distance (float): The distance to move along the line.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: New coordinates of the point.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert points to numpy arrays\n",
    "    p1 = np.array(p1)\n",
    "    p2 = np.array(p2)\n",
    "    point = np.array(point)\n",
    "    \n",
    "    # Calculate direction vector of the line\n",
    "    direction = p2 - p1\n",
    "    \n",
    "    # Normalize the direction vector\n",
    "    norm = np.linalg.norm(direction)\n",
    "    direction_normalized = direction / norm\n",
    "    \n",
    "    # Calculate the new point\n",
    "    new_point = point + direction_normalized * distance\n",
    "   \n",
    "    new_x = int(new_point[0])\n",
    "    new_y = int(new_point[1])\n",
    "    \n",
    "    return tuple([new_x,new_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rotated_rectangle(color_image,x1,x2,y1,y2,p_new_1):\n",
    "                angle = -np.degrees(np.arctan2(y2-y1, x2-x1))\n",
    "                \n",
    "                x, y = p_new_1[0], p_new_1[1]\n",
    "\n",
    "                # Define the width and height of the rectangle\n",
    "                width = 80\n",
    "                height = 45\n",
    "\n",
    "                rotation_matrix = cv2.getRotationMatrix2D((x, y), angle, 1)\n",
    "                \n",
    "                corner_1  =[x+width, y-height]\n",
    "                corner_2 = [x+width, y+height]\n",
    "                corner_3 = [x-width, y+height]\n",
    "                corner_4 = [x-width,y-height]\n",
    "                \n",
    "                rect_points = np.array([\n",
    "                corner_1,\n",
    "                corner_2,\n",
    "                corner_3,\n",
    "                corner_4\n",
    "            ])\n",
    "\n",
    "                rotated_rect_points = np.dot(rect_points, rotation_matrix[:, :2].T) + rotation_matrix[:, 2]\n",
    "                \n",
    "                rotated_rect_points = rotated_rect_points.astype(int)\n",
    "\n",
    "                rotated_rect_points[:,0] =  rotated_rect_points[:,0]  #+ x\n",
    "                rotated_rect_points[:,1] =  rotated_rect_points[:,1]  #+ y\n",
    "                \n",
    "                cv2.polylines(color_image, [rotated_rect_points], isClosed=True, color=(125, 125, 0), thickness=10)\n",
    "\n",
    "                return rect_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corner_points(color_image,box,hull):\n",
    "                x_corner_1 = 0\n",
    "                y_corner_1 = 0\n",
    "                reference_distance_corener_1 = 5000\n",
    "                \n",
    "                x_corner_2 = 0\n",
    "                y_corner_2 = 0\n",
    "                reference_distance_corener_2 = 5000\n",
    "                \n",
    "                x_corner_3 = 0\n",
    "                y_corner_3 = 0\n",
    "                reference_distance_corener_3 = 5000\n",
    "                \n",
    "                x_corner_4 = 0\n",
    "                y_corner_4 = 0\n",
    "                reference_distance_corener_4 = 5000\n",
    "                \n",
    "                for j in range(len(hull)):\n",
    "                    p = tuple(hull[j][0])\n",
    "                    x = p[0]\n",
    "                    y = p[1]\n",
    "                    \n",
    "\n",
    "                    distance_corner_1 = calculate_distance(box[0], p)\n",
    "                    distance_corner_2 = calculate_distance(box[1], p)\n",
    "                    distance_corner_3 = calculate_distance(box[2], p)\n",
    "                    distance_corner_4 = calculate_distance(box[3], p)\n",
    "                    \n",
    "                    if distance_corner_1 < reference_distance_corener_1:\n",
    "                        x_corner_1 = x\n",
    "                        y_corner_1 = y\n",
    "                        reference_distance_corener_1 = distance_corner_1\n",
    "                        \n",
    "                    if distance_corner_2 < reference_distance_corener_2:\n",
    "                        x_corner_2 = x\n",
    "                        y_corner_2 = y\n",
    "                        reference_distance_corener_2 = distance_corner_2\n",
    "                    \n",
    "                    if distance_corner_3 < reference_distance_corener_3:\n",
    "                        x_corner_3 = x\n",
    "                        y_corner_3 = y\n",
    "                        reference_distance_corener_3 = distance_corner_3\n",
    "                        \n",
    "                      \n",
    "                    if distance_corner_4 < reference_distance_corener_4:\n",
    "                        x_corner_4 = x\n",
    "                        y_corner_4 = y\n",
    "                        reference_distance_corener_4 = distance_corner_4\n",
    "\n",
    "\n",
    "                cv2.circle(color_image, box[1], 20, (255, 0, 255), 5) \n",
    "                cv2.circle(color_image, [x_corner_1,y_corner_1], 20, (0, 125, 255), 5) \n",
    "                cv2.circle(color_image, [x_corner_2,y_corner_2], 20, (0, 125, 255), 5) \n",
    "                cv2.circle(color_image, [x_corner_3,y_corner_3], 20, (0, 125, 255), 5) \n",
    "                cv2.circle(color_image, [x_corner_4,y_corner_4], 20, (0, 125, 255), 5) \n",
    "                \n",
    "                \n",
    "        \n",
    "                \n",
    "                corner_1 = [int(x_corner_1), int(y_corner_1)]\n",
    "                corner_2 = [x_corner_2, y_corner_2]\n",
    "                corner_3 = [x_corner_3, y_corner_3]\n",
    "                corner_4 = [x_corner_4, y_corner_4]\n",
    "                \n",
    "                return corner_1, corner_2, corner_3, corner_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shifted_points(corner_1,corner_2,corner_3, corner_4, edge_scale_factor_1=0.2, edge_scale_factor_2 = 0.2, edge_scale_factor_3 = 0.2, edge_scale_factor_4 = 0.2):\n",
    "    side_lengths = [\n",
    "                    (distance(corner_1, corner_2), (corner_1, corner_2)),\n",
    "                    (distance(corner_2, corner_3), (corner_2, corner_3)),\n",
    "                    (distance(corner_3, corner_4), (corner_3, corner_4)),\n",
    "                    (distance(corner_4, corner_1), (corner_4, corner_1)),\n",
    "                ]\n",
    "\n",
    "    #Box Stuff\n",
    "    # Calculate the lengths of the sides\n",
    "\n",
    "    # Sort sides by length in descending order and get the two longest sides\n",
    "    longest_sides = sorted(side_lengths, key=lambda x: x[0], reverse=True)[:2]\n",
    "\n",
    "    # Extract the lengths and coordinates of the two longest sides\n",
    "\n",
    "    longest_sides_coords = [side[1] for side in longest_sides]\n",
    "    \n",
    "    x1 = longest_sides_coords[0][0][0]\n",
    "    y1 = longest_sides_coords[0][0][1]\n",
    "    \n",
    "    x2 = longest_sides_coords[0][1][0]\n",
    "    y2 = longest_sides_coords[0][1][1]\n",
    "    \n",
    "    x3 = longest_sides_coords[1][0][0]\n",
    "    y3 = longest_sides_coords[1][0][1]\n",
    "    \n",
    "    x4 = longest_sides_coords[1][1][0]\n",
    "    y4 = longest_sides_coords[1][1][1]\n",
    "\n",
    "    \n",
    "    p1, p2  = [x1,y1], [x2,y2]\n",
    "    p3,p4 = [x3,y3], [x4,y4]\n",
    "    \n",
    "\n",
    "    d1 = calculate_distance(p1,p2)\n",
    "    d2 = calculate_distance(p3,p4)\n",
    "  \n",
    "    p_new_1 = move_point_on_line(p1, p2, p1, d1 * edge_scale_factor_1)\n",
    "    p_new_2 = move_point_on_line(p1, p2, p2, -d1* edge_scale_factor_2)\n",
    "    p_new_3 = move_point_on_line(p3,p4, p3, d2*edge_scale_factor_3)\n",
    "    p_new_4 = move_point_on_line(p3,p4,p4,d2*-edge_scale_factor_4 )\n",
    "    \n",
    "    return p_new_1, p_new_2, p_new_3, p_new_4, d1,d2, x1,y1,x2,y2,x3,y3,x4,y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scale_factors(corner_1, corner_2, corner_3, corner_4):\n",
    "    \n",
    "                m1,q1 = line_from_points(corner_1,corner_3)\n",
    "                m2,q2 = line_from_points(corner_2,corner_4)\n",
    "    \n",
    "                center = get_line_intercection(m1,m2,q1,q2)\n",
    "                #cv2.circle(color_image, center,20, (50, 255, 0), 5) \n",
    "                \n",
    "                diagonal_distance_13 = calculate_distance(corner_1,corner_3)\n",
    "                diagonal_distance_24 = calculate_distance(corner_2,corner_4)\n",
    "                distance_1 = calculate_distance(corner_1,center)\n",
    "                distance_2 = calculate_distance(corner_3,center)\n",
    "                distance_3 = calculate_distance(corner_2,center)\n",
    "                distance_4 = calculate_distance(corner_4,center)\n",
    "\n",
    "                factor_1 = distance_1 / diagonal_distance_13 * 0.4\n",
    "                factor_2 = distance_2 / diagonal_distance_13 * 0.4\n",
    "                factor_3 = distance_3 / diagonal_distance_24 * 0.4\n",
    "                factor_4 = distance_4 / diagonal_distance_24 * 0.4\n",
    "                \n",
    "                return factor_1, factor_2, factor_3, factor_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Videocapture = False\n",
    "\n",
    "if Videocapture == True:  \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Adjust codec as needed (e.g., 'XVID', 'MJPG', 'MP4V')\n",
    "    out_color = cv2.VideoWriter('Demo/BinDetection_v1_models_.avi', fourcc,30.0, (1920, 1080))\n",
    "# Check if the VideoWriter object is successfully initialized\n",
    "    if not out_color.isOpened():\n",
    "        print(\"Error: Could not open video writer.\")\n",
    "\n",
    "\n",
    "\n",
    "save_dir = 'batch2/negative'\n",
    "os.makedirs(save_dir,exist_ok = True)\n",
    "image_count = 0\n",
    "Save_images = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmamie\\AppData\\Local\\Temp\\ipykernel_10556\\2748353546.py:25: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nmamie\\AppData\\Local\\anaconda3\\envs\\binsertion-env\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nmamie\\AppData\\Local\\anaconda3\\envs\\binsertion-env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\nmamie\\AppData\\Local\\anaconda3\\envs\\binsertion-env\\lib\\threading.py\", line 870, in run\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     25\u001b[0m color_image, depth_image \u001b[38;5;241m=\u001b[39m frame_queue\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m---> 27\u001b[0m depth_colormap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mapplyColorMap(\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvertScaleAbs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m)\u001b[49m, cv2\u001b[38;5;241m.\u001b[39mCOLORMAP_JET)\n\u001b[0;32m     28\u001b[0m masked_color_image, hull,box\u001b[38;5;241m=\u001b[39m cut_region(depth_image,color_image,min_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m####################################\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#get Hull corner\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\nmamie\\VSCode\\BinInsertion_main\\video_capture.py\", line 14, in capture_frames\n",
      "    frames = pipeline.wait_for_frames()\n",
      "RuntimeError: wait_for_frames cannot be called before start()\n"
     ]
    }
   ],
   "source": [
    "#Initialize\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, 1920, 1080, rs.format.bgr8, framerate = 30)\n",
    "config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, framerate = 30)\n",
    "\n",
    "pipeline.start(config)\n",
    "\n",
    "frame_queue = queue.Queue(maxsize=1) \n",
    "#create align object\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "\n",
    "capture_thread = threading.Thread(target=capture_frames, args = (pipeline,frame_queue,align), daemon=True)\n",
    "\n",
    "capture_thread.start()\n",
    "\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "            if not frame_queue.empty():\n",
    "        \n",
    "                start = time.time()\n",
    "                color_image, depth_image = frame_queue.get()\n",
    "     \n",
    "                depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.25), cv2.COLORMAP_JET)\n",
    "                masked_color_image, hull,box= cut_region(depth_image,color_image,min_depth = 0,max_depth = 0.8)\n",
    "                \n",
    "                ####################################\n",
    "\n",
    "                #get Hull corner\n",
    "              \n",
    "                corner_1, corner_2, corner_3, corner_4 = get_corner_points(color_image, box, hull)\n",
    "\n",
    "                ############ draw rectangle end\n",
    "                \n",
    "                #get_scale_factor\n",
    "\n",
    "                \n",
    "                factor_1, factor_2, factor_3, factor_4 = get_scale_factors(corner_1, corner_2, corner_3, corner_4)\n",
    "\n",
    "                \n",
    "                #line1 = (corner_1,corner_3)\n",
    "                #line2 = (corner_2,corner_4)\n",
    "                \n",
    "                #if line1:   \n",
    "                   # cv2.line(color_image, line1[0], line1[1], (255, 255, 0), 5)\n",
    "                #if line2: \n",
    "                   # cv2.line(color_image, line2[0], line2[1], (125, 0, 125), 5)\n",
    "                    \n",
    "                #######################################\n",
    "                \n",
    "\n",
    "                p_new_1, p_new_2, p_new_3, p_new_4, d1,d2, x1,y1,x2,y2,x3,y3,x4,y4 = get_shifted_points(corner_1,corner_2,corner_3, corner_4, factor_1, factor_2, factor_4, factor_3)\n",
    "\n",
    "                ########## draw rectangle\n",
    "      \n",
    "                rect_1 = draw_rotated_rectangle(color_image,x1,x2,y1,y2,p_new_1)\n",
    "                rect_2 = draw_rotated_rectangle(color_image,x1,x2,y1,y2,p_new_2)\n",
    "                rect_3 = draw_rotated_rectangle(color_image,x3,x4,y3,y4,p_new_3)\n",
    "                rect_4 = draw_rotated_rectangle(color_image,x3,x4,y3,y4,p_new_4)\n",
    "                \n",
    "   \n",
    "                scale_factor = 0.8\n",
    "                resized_image = cv2.resize(color_image,None,fx =  scale_factor,fy = scale_factor)\n",
    "                cv2.imshow('masked image', resized_image)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "      \n",
    "\n",
    "finally:\n",
    "    # Stop streaming\n",
    "    pipeline.stop()\n",
    "        \n",
    "    if Videocapture == True:\n",
    "        out_color.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 414,  182],\n",
       "       [1594,  165],\n",
       "       [1606,  974],\n",
       "       [ 426,  991]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "binsertion-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
